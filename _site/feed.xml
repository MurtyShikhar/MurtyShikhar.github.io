<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2023-09-25T17:14:58-04:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
</subtitle><entry><title type="html">Compositionality and Generalization in Transformers</title><link href="http://localhost:4000/blog/2023/compositionality/" rel="alternate" type="text/html" title="Compositionality and Generalization in Transformers" /><published>2023-09-21T00:00:00-04:00</published><updated>2023-09-21T00:00:00-04:00</updated><id>http://localhost:4000/blog/2023/compositionality</id><content type="html" xml:base="http://localhost:4000/blog/2023/compositionality/"><![CDATA[<p>Coming soon!</p>]]></content><author><name></name></author><category term="interpretability" /><category term="compositionality" /><summary type="html"><![CDATA[What internal structures do transformer models learn that helps them generalize so well?]]></summary></entry></feed>