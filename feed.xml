<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://murtyshikhar.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://murtyshikhar.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-02-06T22:31:39+00:00</updated><id>https://murtyshikhar.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Compositionality and Generalization in Transformers</title><link href="https://murtyshikhar.github.io/blog/2023/compositionality/" rel="alternate" type="text/html" title="Compositionality and Generalization in Transformers"/><published>2023-09-21T00:00:00+00:00</published><updated>2023-09-21T00:00:00+00:00</updated><id>https://murtyshikhar.github.io/blog/2023/compositionality</id><content type="html" xml:base="https://murtyshikhar.github.io/blog/2023/compositionality/"><![CDATA[<p>Coming soon!</p>]]></content><author><name></name></author><category term="interpretability"/><category term="compositionality"/><summary type="html"><![CDATA[What internal structures do transformer models learn that helps them generalize so well?]]></summary></entry></feed>